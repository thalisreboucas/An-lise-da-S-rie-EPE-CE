---
title: "Análise da Série de Consumo de Energia Elétrica no Ceará"
author: "Thalis Rebouças"
subtitle: "CC0308 - 2025 | Julho 2025 <br><br> Slides:**https://thalisreboucas.github.io/Analise-da-Serie-EPE-CE/#/**"
format: 
  revealjs:
    logo: "images/logo.png"
    width: 1600
    height: 900
    self-contained: false
    incremental: false
    footer: "Slides por Thalis Rebouças, feito em [Quarto](https://quarto.org/docs/presentations/revealjs/index.html). Código disponível [no GitHub](https://github.com/thalisreboucas/Analise-da-Serie-EPE-CE)."
    theme: ["custom.scss"]
    slide-number: c/t
    show-slide-number: all
    hash-type: number
    preview-links: false
---

## Sumário de aprendizagem

::: {style="font-size: 80%;"}
-   Resumo Geral

     1. Motivo da Escolha da Série

     2. Apresentação da Série

-   Estimação dos Modelos de Série Temporal

     3. Método de Suavização Exponencial
     
     4. Metodologia Box-Jenkins
     
     5. Análise de Intervenções
-   Conclusão
    
    7. Conclusão das análises e modelos
    
    8. Referências

:::

# Vamos lá!

# Motivo da Escolha da Série

## Motivo da  <br> Escolha da Série:

**Qual série ?**

$$Z_t = \text{Consumo Mensal de Energia Elétrica no Ceará (Sistema Simples) (2004-2025)}$$

<!--# Descrito por hugo -->
**Por que Análisar ?**

- Identificar padrões e tendências no consumo energético.

- Apoiar políticas públicas para eficiência energética.

- Entender como fatores como o cresimento da população e sazonalidade influenciam o consumo.

# Apresentação da série.

## Apresentação da série:

- É uma série do EPE(Empresa de Pesquisa Energética) do Ministério de Minas e Energia (MME).

- É um dado público disponível desde de 2004 de todos os estados e tipo de consumo [neste link](https://www.epe.gov.br/_layouts/download.aspx?sourceURL=%2Fsites-pt%2Fpublicacoes-dados-abertos%2Fpublicacoes%2FDocuments%2FCONSUMO%2520MENSAL%2520DE%2520ENERGIA%2520EL%25c3%2589TRICA%2520POR%2520CLASSE.xlsx).

Neste caso, vou me restringir a análisar apenas o consumo do Ceará na parte de consumo de energia elétrica na rede (MWh) de Sistema Simples.

- É possivél entender melhor os dados e análises que o governo faz [neste link](https://encurtador.com.br/6qoRG).


## Apresentação da série:

::: {style="font-size: 70%;"}
A série começa em janeiro de 2004 e vai até março de 2025,com isso tem cerca de 255 observações,vamos olhar o **gráfico da série:**

:::

```{r , fig.align='center'}

pacman::p_load(forecast, tseries, ggplot2, patchwork,gridExtra, urca, lubridate, FinTS, zoo,tibble,readxl,datawirzad,tidyverse,timetk,tseries,TSA,tsoutliers,)



# 2. CARREGAMENTO E PREPARAÇÃO DOS DADOS
#-----------------------------------------------------------------------
# Carregar o arquivo CSV
file_path <- "C:/Users/thali/Desktop/Área de Trabalho/Serie temporal/Análise de Energia eletrica industrial do Ceará/Slide/Analise-da-Serie-EPE-CE/Bases/CMEIC.xlsx"
dados_completos <- read_excel(file_path)

# Renomear colunas para facilitar o manuseio (assumindo a ordem das colunas)
colnames(dados_completos) <- c("data", "consumo_gwh")

# Filtrar dados para o estado do Ceará (CE)
ceara_data <- dados_completos %>%
  mutate(data = as.Date(data)) %>%
  arrange(data)

# Gráfico da série temporal completa
ggplot(ceara_data, aes(x = data, y = consumo_gwh)) +
  geom_line(color = "#000000", size = 1) +
  labs(title = "Consumo Mensal de Energia Elétrica no Ceará (Sistema Simples) (2004-2025)",
       subtitle = "Fonte: Empresa de Pesquisa Energética (EPE)",
       x = "Ano",
       y = "Consumo (MWh)") +
  theme_minimal()
```
## Apresentação da série:

Fazendo o gráfico box-plot separados por mês,quadrimestre e ano.

```{r, fig.align='center'}
teste = ceara_data %>%  rename( date = data , value = consumo_gwh)


teste %>%  plot_seasonal_diagnostics(date, value, .interactive = FALSE) 
```
Percebemos um aumento nos últimos meses do ano e valores de outliers em alguns anos.


## Divisão da Série:

**Fazendo a divisão da série em teste e treino**
::: {style="font-size: 50%;"}
Será feita um divisão na série em teste e treino, onde:

- A série de treino vai até o final do ano de 2022

- A série de teste começa do ano de 2023 até março de 2025

Assim sendo um divisão de 27 observações a serem prevista nos teste dos modelos
:::
```{}
# A série começa em Janeiro de 2004
ts_ceara <- ts(ceara_data$consumo_gwh, start = c(2004, 1), frequency = 12)
# 2. Criar o conjunto de TREINO usando a função window()
treino <- window(ts_ceara, end = c(2022, 12))
# 3. Criar o conjunto de TESTE usando a função window()
teste <- window(ts_ceara, start = c(2023, 1), end = c(2025, 3))
```

```{r}
# A série começa em Janeiro de 2004
ts_ceara <- ts(ceara_data$consumo_gwh, start = c(2004, 1), frequency = 12)
# 2. Criar o conjunto de TREINO usando a função window()
treino <- window(ts_ceara, end = c(2022, 12))
# 3. Criar o conjunto de TESTE usando a função window()
teste <- window(ts_ceara, start = c(2023, 1), end = c(2025, 3))

# --- Função Aprimorada ---

#' Gera um painel de diagnóstico para uma série temporal.
#'
#' @param ts_object Um objeto de série temporal (classe ts).
#' @param titulo Um título geral para o painel de gráficos.
#' @return Um objeto de gráfico patchwork contendo os diagnósticos.

gerar_diagnostico_ts <- function(ts_object, titulo = "Painel de Diagnóstico da Série Temporal") {
  
# 2. Gráfico da Função de Autocorrelação (ACF)
  p1 <- ggAcf(ts_object, lag.max = 36) +
    labs(title = "Autocorrelação (ACF)") +
    theme_light()
  
  # 3. Gráfico da Função de Autocorrelação Parcial (PACF)
  p2 <- ggPacf(ts_object, lag.max = 36) +
    labs(title = "Autocorrelação Parcial (PACF)") +
    theme_light()
  
 
  # 5. Organizar os gráficos usando patchwork
  layout <- (p1 | p2) 
  
  # Adicionar um título geral ao painel
  plot_final <- layout + plot_annotation(title = titulo,
                                        theme = theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold")))
  
  return(plot_final)
}



gerar_diagnostico2_ts <- function(ts_object, titulo = "Painel de Diagnóstico da Série Temporal") {
  
# 2. Gráfico da Função de Autocorrelação (ACF)
  p1 <- ggAcf(ts_object, lag.max = 36) +
    labs(title = "Autocorrelação (ACF)") +
    theme_light()
  
  # 3. Gráfico da Função de Autocorrelação Parcial (PACF)
  p2 <- ggPacf(ts_object, lag.max = 36) +
    labs(title = "Autocorrelação Parcial (PACF)") +
    theme_light()
  
  p3 <- autoplot(ts_object) +   geom_line(color = "#000000", size = 1) +  labs(title = "Gráfico da Série",
       x = "Ano",
       y = "Consumo (MWh)") +
    theme_light()
 
  # 5. Organizar os gráficos usando patchwork
  layout <- p3 / (p1 | p2)
  
  # Adicionar um título geral ao painel
  plot_final <- layout + plot_annotation(title = titulo,
                                        theme = theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold")))
  
  return(plot_final)
}





```

# Método de Suavização Exponencial

## Método de Suavização Exponencial

Passo a passo:

- A metodologia de suavização exponencial foi aplicada usando a função ets() do R.

Esta função testa diferentes combinações de componentes de Erro (E), Tendência (T) e Sazonalidade (S), selecionando o modelo que minimiza um critério de informação, como o AIC (Critério de Informação de Akaike). 

O modelo é ajustado apenas com o conjunto de treino, será selecionado apenas o que tiver o melhor AIC definido pela a função do `ETS()` do **R**.


## Método de Suavização Exponencial

Fazendo a utilização da chamada do modelo temos:


```{r}

modelo_ets <- ets(treino)
#summary(modelo_ets) 
#checkresiduals(modelo_ets)

```

```
modelo_ets <- ets(treino)

```

- Que o melhor modelo sugerido foi o ETS(M,Ad,M)

| Componente           | Tipo                | Significado                                                   |
| -------------------- | ------------------- | ------------------------------------------------------------- |
| **Erro (E)**         | M: Multiplicativo   | A variabilidade aumenta com o nível da série                  |
| **Tendência (T)**    | Ad: Aditiva Damping | Tendência aditiva com amortecimento (freia ao longo do tempo) |
| **Sazonalidade (S)** | M: Multiplicativa   | Sazonalidade proporcional ao nível da série                   |

## Método de Suavização Exponencial

- Formula do Modelo:

\begin{align*}
\textbf{Previsão:} \quad
\hat{y}_{t+h} &= (l_t + \phi^h b_t) \cdot s_{t+h-m(k+1)} \\[1em]

\textbf{Atualização do nível:} \quad
l_t &= \alpha \cdot \frac{y_t}{s_{t-m}} + (1 - \alpha)(l_{t-1} + \phi b_{t-1}) \\[1em]

\textbf{Atualização da tendência:} \quad
b_t &= \beta \cdot (l_t - l_{t-1}) + (1 - \beta) \cdot \phi b_{t-1} \\[1em]

\textbf{Atualização da sazonalidade:} \quad
s_t &= \gamma \cdot \frac{y_t}{l_t} + (1 - \gamma) \cdot s_{t-m}
\end{align*}




## Método de Suavização Exponencial


```
summary(modelo_ets)

```
::: {style="font-size: 50%;"}
- Modelo selecionado pelo melhor AIC

* **Alpha (nível):** $\alpha = 0,7001$
* **Beta (tendência):** $\beta = 0,0038$
* **Gamma (sazonalidade):** $\gamma = 0,0001$
* **Damping:** $\phi = 0,9787$
* **Nível inicial:** $l_0 = 506720,43$
* **Tendência inicial:** $b_0 = 3288,48$
* **Desvio Padrão dos erros:** $0,0313$
* **AIC:** $5878,418$

**Sazonalidade inicial:** $s_1 = 1,033, \ldots, s_{12} = 1,0149$
:::

## Método de Suavização Exponencial
::: {style="font-size: 50%;"}
**Métricas de desempenho no conjunto de treino:**

* RMSE: 26.608,53

* MAE: 19.550,13

* MAPE: 2,29% ⇒ Erro percentual muito baixo

* ACF dos resíduos: 0,066 ⇒ Baixa autocorrelação

:::
## Método de Suavização Exponencial

- Formula do modelo

\begin{align*}
\hat{y}_{t+h} &= \left( 506720{,}43 + 0{,}9787^h \cdot 3288{,}48 \right) \cdot s_{t+h-12(k+1)} \\
l_t &= 0{,}7001 \cdot \frac{y_t}{s_{t-12}} + (1 - 0{,}7001)(l_{t-1} + 0{,}9787 \cdot b_{t-1}) \\
b_t &= 0{,}0038 \cdot (l_t - l_{t-1}) + (1 - 0{,}0038) \cdot 0{,}9787 \cdot b_{t-1} \\
s_t &= 0{,}0001 \cdot \frac{y_t}{l_t} + (1 - 0{,}0001) \cdot s_{t-12}
\end{align*}


## Método de Suavização Exponencial



```{r ,fig.align='center'}
gerar_diagnostico2_ts(modelo_ets$residuals) 
```

* Modelo quase ajustado

* Captura tendência suavizada e sazonalidade proporcional fraca

* Resíduos sem padrão aparente

## Método de Suavização Exponencial

```{r, fig.align='center'}

# Realizar a previsão para os próximos 27 meses 
previsao_ets <- forecast(modelo_ets, h = 27)

# Gráfico da previsão vs. dados de teste 
autoplot(previsao_ets) +
  autolayer(teste, series="Dados Reais") +
  labs(title='Gráfico 1: Previsão com ETS(M,Ad,M) vs. Dados de Teste', 
       x='Ano', y='Índice',
       caption = 'Linha azul: Previsão ETS. Sombreado: Intervalos de Confiança.') +
  theme_minimal()
```

## Método de Suavização Exponencial

- Acurácia do Modelo ETS no Conjunto de Teste

```
print(acuracia_ets)
```

```{r ,fig.align='center'}
# Obter as medidas de ajuste no conjunto de teste 
acuracia_ets <- accuracy(previsao_ets, teste)
print(acuracia_ets)


```

O modelo apresenta um desempenho ruim no conjunto de teste. Embora tenha se ajustado razoavelmente bem aos dados de treinamento, ele não conseguiu generalizar essa performance para os dados futuros (o conjunto de teste).

O modelo está superajustado (overfit) e tem um desempenho de previsão muito ruim, sendo inferior a um método de benchmark simples.


# Metodologia Box-Jenkins



## Metodologia Box-Jenkins


 Uma abordagem sistemática para análise e previsão de Séries Temporais



 **Modelo Central: ARIMA(p, d, q)**

O objetivo é encontrar o modelo que melhor se ajusta aos dados.

* **AR (p): Autoregressivo**
    * Dependência dos **valores passados** da própria série.
* **I (d): Integrado**
    * Número de **diferenciações** necessárias para tornar a série estacionária.
* **MA (q): Média Móvel**
    * Dependência dos **erros de previsão passados**.


## Metodologia Box-Jenkins

::: {style="font-size: 50%;"}
 **Processo Iterativo em 4 Etapas**

1.  **Identificação do Modelo**
    * Verificar e ajustar a **estacionariedade** da série (usando diferenciação `d`).
    * Analisar gráficos de **Autocorrelação (FAC)** e **Autocorrelação Parcial (FACP)** para sugerir as ordens `p` e `q`.

2.  **Estimação dos Parâmetros**
    * Calcular os coeficientes do modelo ARIMA(p, d, q) candidato.

3.  **Verificação de Diagnóstico**
    * Analisar os **resíduos** do modelo: eles devem se comportar como ruído branco (aleatórios e sem padrão).
    * Se o modelo for inadequado, retorna-se à Etapa 1.

4.  **Previsão**
    * Com um modelo validado, utilizá-lo para prever valores futuros.



**Pontos-Chave**

* **Guiado pelos Dados:** A estrutura do modelo é definida pelos padrões encontrados nos próprios dados.
* **Iterativo:** É um ciclo de identificação, ajuste e verificação.
* **Objetivo:** Construir um modelo estatisticamente robusto para gerar previsões precisas.

:::



## Análises Primárias da série e Ajustes:

Podemos decompor a serie para ver a sazonalidade e estacionáridade,

```{r ,fig.align='center'}
# A série começa em Janeiro de 2004
ts_ceara <- ts(ceara_data$consumo_gwh, start = c(2004, 1), frequency = 12)
# 2. Criar o conjunto de TREINO usando a função window()
treino <- window(ts_ceara, end = c(2022, 12))
# 3. Criar o conjunto de TESTE usando a função window()
teste <- window(ts_ceara, start = c(2023, 1), end = c(2025, 3))


# Decomposição da série temporal usando STL (Seasonal and Trend decomposition using Loess)
decomposicao <- stl(ts_ceara, s.window = "periodic")

autoplot(decomposicao, colour = "#0072B2") +
  
  # 1. Adicionar títulos, subtítulos e legendas mais descritivas
  labs(
    title = "Decomposição STL da Série Temporal",
    subtitle = "Componentes: Dados, Tendência, Sazonalidade e Resíduo",
    x = "Ano",
    y = ""  # Deixamos em branco para que os nomes dos painéis sirvam como rótulos
  ) +
  
  # 2. Personalizar os elementos do tema do gráfico
  theme_minimal() +
  theme(
    # Formatação do título principal
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "gray20"),
    
    # Formatação do subtítulo
    plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray30"),
    
    # Formatação do título do eixo X
    axis.title.x = element_text(size = 12, face = "italic"),
    
    # Formatação do texto dos painéis (Data, Trend, etc.)
    strip.text = element_text(size = 11, face = "bold", color = "gray10"),
    
    # Ajustar as linhas de grade para um visual mais limpo
    panel.grid.major = element_line(colour = "gray90"),
    panel.grid.minor = element_blank(), # Remover linhas de grade menores
    
    # Adicionar um espaço entre os painéis para melhor separação
    panel.spacing = unit(1.5, "lines") 
  )
```
**Percebe-se um tendência práticamente linear cresente e uma série serrote, vamos olhar os lags para ver se tem tendência.**


## Análises Primárias da série e Ajustes:

```
adf.test(treino) 
kpss.test(treino) 

```

```{r}
adf.test(treino) 
kpss.test(treino) 

```

Com base nos resultados dos testes, a sua série temporal `treino` **não é estacionária**.

## Análises Primárias da série e Ajustes:

::: {style="font-size: 50%;"}

Ambos os testes, apesar de terem hipóteses opostas, apontam para a mesma conclusão.

***

 **Teste Augmented Dickey-Fuller (ADF)**

O teste ADF busca evidências de que a série *é estacionária*.

* **Hipótese Nula ($H_0$)**: A série **não é estacionária** (possui raiz unitária).
* **Seu resultado**: O p-valor foi de **0.09388**.

Como o p-valor (0.09) é **maior** que o nível de significância padrão (0.05), você **falha em rejeitar** a hipótese nula. Isso significa que, segundo o teste ADF, a série é considerada **não estacionária**.

***

 **Teste KPSS**

O teste KPSS, por outro lado, busca evidências de que a série *não é estacionária*.

* **Hipótese Nula ($H_0$)**: A série **é estacionária**.
* **Seu resultado**: O p-valor foi de **0.01**.

Como o p-valor (0.01) é **menor** que o nível de significância (0.05), você **rejeita** a hipótese nula. Isso significa que o teste KPSS também conclui que a série é **não estacionária**.

**Conclusão Final**

Ambos os testes confirmam que a série `treino` **não é estacionária**. O próximo passo na modelagem ARIMA seria aplicar a **diferenciação** na série para tentar torná-la estacionária. 👍

:::




## Análises Primárias da série e Ajustes:

Análisando os lags da série:

```
gerar_diagnostico_ts(treino)
```

```{r ,fig.align='center'}

gerar_diagnostico_ts(treino)
```
Temos um forte evidência do modelo ser um autoregressivo de ordem 1 ou 2 e que a parte de médias móveis precisa tem um tratamento para aparecer, mesmo que no limte um sazonalidade no lag 12 ~ 14.


## Análises Primárias da série e Ajustes:

Análisando os dados da Série da **primeira diferança**:

```
ts_diff= diff(treino)
gerar_diagnostico2_ts(ts_diff)
adf.test(ts_diff)
kpss.test(ts_diff)
```


```{r, fig.align='center'}

ts_diff= diff(treino)
gerar_diagnostico2_ts(ts_diff)
#adf.test(ts_diff)
#kpss.test(ts_diff)

```
## Análises Primárias da série e Ajustes:

**Principais Observações**

* **Estacionariedade:** A série se tornou estacionária após **1 diferenciação** (`d=1`).

* **Sazonalidade Anual:** Padrão sazonal muito forte, com "spikes" significativos nos **lags 12 e 24** nos gráficos ACF e PACF.
    * O spike claro no **PACF** no lag 12 sugere um componente **AR Sazonal (P=1)**.

* **Componente Não-Sazonal:** O **PACF** corta abruptamente após o lag 1.
    * Isso sugere um componente **AR(1) (p=1)**.


## Análises Primárias da série e Ajustes:

::: {style="font-size: 50%;"}
**Modelo Proposto Inicial: $SARIMA(1, 1, 1)(1, 0,0)^{12}$**

| Componente | Ordem | Justificativa |
| :--- | :---: | :--- |
| **p** (AR Não-sazonal) | **1** | Corte no PACF no lag 1 |
| **d** (Diferenciação) | **1** | Aplicada para obter estacionariedade |
| **q** (MA Não-sazonal) | **1** | Ponto de partida simples |
| **P** (AR Sazonal) | **1** | Spike significativo no PACF no lag 12 |
| **D** (Dif. Sazonal) | **0** | Não parece necessária a primeira vista |
| **Q** (MA Sazonal) | **0** | Ponto de partida simples |
| **s** (Período Sazonal) | **12**| Padrão anual |

temos uma melhora da série e os testes de Dickey-Fuller e KPSS deu que a série é estacionaria.

:::


 Os testes de Dickey-Fuller e KPSS deu que a série é estacionaria.


## Sugestão Modelo 1
::: {style="font-size: 50%;"}

A fórmula é:

$SARIMA(1, 1, 1)(1, 0, 0)_{12}$

### Detalhamento dos Componentes

* **SARIMA**: Sigla para *Seasonal AutoRegressive Integrated Moving Average*.
* **(p, d, q) = (1, 0, 1)**: Esta é a parte **não sazonal** do modelo.
    * `p=1`: Um termo autorregressivo (AR).
    * `d=0`: Uma diferenciação regular para tornar a série estacionária.
    * `q=1`: Nenhum termo de média móvel (MA).
* **(P, D, Q)m = (1, 0, 0)m**: Esta é a parte **sazonal** do modelo.
    * `P=1`: Um termo autorregressivo sazonal.
    * `D=0`: Nenhuma diferenciação sazonal.
    * `Q=0`: Nenhum termo de média móvel sazonal.
    * `m`: Representa o período da sazonalidade (por exemplo, `m=12` para dados mensais).

:::

## Sugestão Modelo 1
```
Modelo1 <- Arima(treino, order = c(1, 1, 1), seasonal = c(1,0,0))

summary(Modelo1)
```

```{r}
Modelo1 <- Arima(treino, order = c(1, 1, 1), seasonal = c(1,0,0))

summary(Modelo1)
```
## Sugestão Modelo 1

Equação Proposta 1:
$$(1 - \phi_1 B)(1 - \Phi_1 B^{12})(1-B) Y_t = (1 + \Theta_1 B) a_t$$

Substiduindo os valores obtidos, temos: 

$$
(1 - 0,7196 B)(1 - 0,2938B^{12})(1-B)Y_t = (1 -0.8920 B) a_t
$$

## Diagnóstico Modelo 1

```{r, fig.align='center'}
gerar_diagnostico2_ts(Modelo1$residuals) 

```

Os gráficos indicam que os resíduos do modelo se comportam como ruído branco, sem autocorrelação, sugerindo um bom ajuste,mas que pode ser melhorado.


# Sugestão de um Modelo 2


## Análises Primárias da série e Ajustes:

Análisando os dados da Série da **primeira diferança normal e uma sazonal**:


```

ts_diff_12 = diff(diff(ts_ceara),12)
gerar_diagnostico2_ts(ts_diff_12 )
adf.test(ts_diff_12)
kpss.test(ts_diff_12)
```

```{r, fig.align='center'}

ts_diff_12 = diff(diff(ts_ceara),12)

gerar_diagnostico2_ts(ts_diff_12 )
#adf.test(ts_diff_12)
#kpss.test(ts_diff_12)

```



## Sugestão Modelo 2

::: {style="font-size: 50%;"}

A fórmula é:

$SARIMA(1, 1, 1)(1, 1, 1)_{12}$

### Detalhamento dos Componentes

* **SARIMA**: Sigla para *Seasonal AutoRegressive Integrated Moving Average*.
* **(p, d, q) = (1, 0, 1)**: Esta é a parte **não sazonal** do modelo.
    * `p=1`: Um termo autorregressivo (AR).
    * `d=1`: Uma diferenciação regular para tornar a série estacionária.
    * `q=1`: Uma termo de média móvel (MA).
* **(P, D, Q)m = (1, 0, 0)m**: Esta é a parte **sazonal** do modelo.
    * `P=1`: Um termo autorregressivo sazonal.
    * `D=1`: Um diferenciação sazonal.
    * `Q=1`: Um termo de média móvel sazonal.
    * `m`: Representa o período da sazonalidade (por exemplo, `m=12` para dados mensais).

:::
$$
(1 - \phi_1 B)(1 - \Phi_1 B^{12})(1-B)(1-B^{12}) Y_t = (1 + \theta_1 B)(1 + \Theta_1 B^{12}) a_t
$$

## Sugestão Modelo 2

```
Modelo2 <- Arima(treino, order = c(1, 1, 1), seasonal = c(1,1,1))

summary(Modelo2)
```


```{r}
Modelo2 <- Arima(treino, order = c(1, 1, 1), seasonal = c(1,1,1))

summary(Modelo2)
```
::: {style="font-size: 60%;"}
O modelo SARIMA(1,1,1)(1,1,1)[12] apresenta um excelente ajuste aos dados de treinamento, com resíduos que se comportam como ruído branco. No entanto, o modelo é ligeiramente mais complexo do que o necessário, pois um de seus coeficientes não é estatisticamente significativo, sugerindo que uma versão simplificada seria mais adequada (parcimoniosa)
:::

## Sugestão Modelo 2

```{r, fig.align='center'}
gerar_diagnostico2_ts(Modelo2$residuals) 
```
::: {style="font-size: 50%;"}
Gráfico da Série: Os resíduos flutuam aleatoriamente em torno de zero, sem qualquer tendência ou padrão visível.

ACF e PACF: Os gráficos de autocorrelação e autocorrelação parcial mostram que praticamente todos os lags estão dentro dos limites de significância (linhas azuis). Isso indica que não há autocorrelação remanescente, um forte sinal de que os resíduos se comportam como ruído branco.
:::

## Sugestão Modelo 2

Assim esse é o Modelo sugerido ideal ao meu ver,
$$(1 - 0.6463 B)(1 - 0.0834 B^{12})(1-B)(1-B^{12}) Y_t = $$
$$(1 - 0.9003 B)(1 - 0.9975 B^{12}) a_t$$



## Sugestão Modelo 2


```{r, fig.align='center'}
# Ajuste o modelo ARIMA

# Faça a previsão para os próximos 24 períodos (por exemplo, 2 anos)
previsao_modelo2 <- forecast(Modelo2,27)
# Gráfico da previsão vs. dados de teste 
autoplot(previsao_modelo2) +
  autolayer(teste, series="Dados Reais") +
  labs(title='Gráfico 2: Previsão com Sarima(1,1,1)x(1,1,1)12  vs. Dados de Teste', 
       x='Ano', y='Índice',
       caption = 'Linha azul: Previsão ETS. Sombreado: Intervalos de Confiança.') +
  theme_minimal()


```
# Modelo Final 

## Sugestão Modelo Final

o Ajuste para um modelo final foi removido o termo não significativo sar1. O novo candidato, que deve ser o modelo final
é o SARIMA(1,1,1)(0,1,1)[12]

```{r}
Modelo3 <- Arima(treino, order = c(1, 1, 1), seasonal = c(0,1,1))

summary(Modelo3)
```
## Sugestão Modelo Final

```{r}
gerar_diagnostico2_ts(Modelo3$residuals) 
```
## Sugestão Modelo Final

Este modelo SARIMA(1,1,1)(0,1,1)[12] é a versão otimizada e final. Ele é mais simples, todos os seus componentes são significativos, e ele se ajusta melhor aos dados segundo os critérios de informação. O próximo passo é usar este modelo para fazer previsões e avaliar seu desempenho no conjunto de teste.

$$
(1 - 0.6370 B)(1-B)(1-B^{12}) Y_t = (1 - 0.8923 B)(1 - 0.9166 B^{12}) a_t
$$


## Previsão Modelo final
```{r, fig.align='center'}
# Ajuste o modelo ARIMA

# Faça a previsão para os próximos 24 períodos (por exemplo, 2 anos)
previsao_modelo3 <- forecast(Modelo3,27)
# Gráfico da previsão vs. dados de teste 
autoplot(previsao_modelo3) +
  autolayer(teste, series="Dados Reais") +
  labs(title='Gráfico 3: Previsão com Sarima(1,1,1)x(0,1,1)12  vs. Dados de Teste', 
       x='Ano', y='Índice',
       caption = 'Linha azul: Previsão ETS. Sombreado: Intervalos de Confiança.') +
  theme_minimal()


```



# Análise de Intervenções

```
detectAO(Modelo3)
detectIO(Modelo3)
```

```{r}
detectAO(Modelo3)
detectIO(Modelo3)
```
::: {style="font-size: 50%;"}
Este resultado indica que o algoritmo de detecção de outliers encontrou um evento estatisticamente significativo na sua série temporal.

* **Evento Detectado:** Um outlier significativo foi identificado no **ponto de índice 196** da série .

* **Tipo de Outlier:** A mensagem `"No AO detected"` informa que não foram encontrados Outliers Aditivos (pontos isolados atípicos). Portanto, o outlier encontrado no índice 196 é de outro tipo, muito provavelmente uma **Mudança de Nível (Level Shift - LS)**.

* **Significância e Impacto:** O valor `lambda1` (`-4.84`) é a estatística-t do evento. Por ser um valor alto (em módulo), o outlier é **altamente significativo**. O sinal negativo indica que houve uma **queda abrupta e permanente** no nível médio da série a partir do ponto 196.

**Em resumo:** a análise sugere que algo mudou estruturalmente na série no 196º período que é maio de 2020, causando uma queda em seu patamar. Isso deve ser incorporado ao modelo final para melhorar a precisão das previsões.
:::

# Análise de Intervenções

```{r}
# Primeiro, pegamos o tamanho do seu conjunto de treino
n_treino <- length(treino)

# Criamos um vetor de zeros com o mesmo tamanho do treino
# Este será nosso regressor para o outlier
outlier_ao_196 <- rep(0, n_treino)

# Agora, colocamos o valor 1 na posição 196, que é o índice do outlier
outlier_ao_196[196] <- 1
```


```{r}
# Ajuste o modelo SARIMA incluindo o regressor do outlier
# Use a função Arima() do pacote forecast, que lida melhor com xreg
Modelo3_com_outlier <- Arima(treino, 
                             order = c(1, 1, 1), 
                             seasonal = list(order = c(0, 1, 1), period = 12),
                             xreg = outlier_ao_196) 

# Veja o resumo do novo modelo
summary(Modelo3_com_outlier)
```

::: {style="font-size: 50%;"}
O modelo combina uma regressão linear com um modelo **SARIMA `(1,1,1)(0,1,1)[12]`** para capturar a dinâmica dos erros, o que é uma abordagem poderosa.

* **Coeficientes Significativos:** Todos os coeficientes, incluindo o da variável externa (`xreg`), são estatisticamente significativos. Isso indica que a variável `xreg` contribui de forma importante para a previsão.
* **Boa Acurácia:** O erro percentual absoluto médio (**MAPE**) de **2.22%** é geralmente considerado um bom nível de precisão.
* **Resíduos Limpos:** O valor de **ACF1** (-0.02) é muito próximo de zero, sugerindo que não há autocorrelação remanescente nos resíduos. Isso é um forte indicativo de que a estrutura do modelo capturou bem os padrões dos dados.

::: 

# Análise de Intervenções

Fazendo agora o Gráfico de Previsão com a Interveção colocada

```{r}
# Ajuste o modelo ARIMA
# Defina o horizonte de previsão (ex: 24 meses)
h_previsao <- 27

# Crie o xreg para o período futuro. Como o outlier não vai se repetir,
# ele será um vetor de zeros.
xreg_futuro <- rep(0, h_previsao)
# Faça a previsão para os próximos 24 períodos (por exemplo, 2 anos)
previsao_modelo3 <- forecast(Modelo3_com_outlier,27,xreg = xreg_futuro)
# Gráfico da previsão vs. dados de teste 
autoplot(previsao_modelo2) +
  autolayer(teste, series="Dados Reais") +
  labs(title='Gráfico 4: Previsão com Sarima(1,1,1)x(0,1,1)12 Reg vs. Dados de Teste', 
       x='Ano', y='Índice',
       caption = 'Linha azul: Previsão ETS. Sombreado: Intervalos de Confiança.') +
  theme_minimal()
```

## Modelo Final 


::: {style="font-size: 50%;"}

| Componente | Termo na Equação | Valor/Parâmetro Estimado | Descrição |
| :--- | :--- | :--- | :--- |
| **Autorregressivo (AR)** | `(1 - 0.6219 B)` | `φ₁ = 0.6219` | Modela a dependência do valor atual com o do período anterior (memória de curto prazo). |
| **Média Móvel (MA)** | `(1 - 0.8848 B)` | `θ₁ = -0.8848` | Modela a dependência do valor atual com o erro de previsão do período anterior. |
| **Média Móvel Sazonal**| `(1 - 0.9295 B¹²)`| `Θ₁ = -0.9295`| Modela a dependência com o erro de previsão do mesmo mês no ano anterior. |
| **Diferenciação** | `(1 - B)(1 - B¹²)` | N/A (Operadores) | Remove a tendência e a sazonalidade para tornar a série estacionária. |
| **Efeito da Intervenção**| `-64822.33 * ... * P_t`| `ω = -64822.33`| O impacto imediato do evento, causando uma queda de ~64.8k unidades. |
| **Erro Aleatório** | `a_t` | N/A (Variável) | Flutuações imprevisíveis restantes após a modelagem dos outros componentes. |
:::

## Modelo Final 
Esta é a equação do modelo final com intervenção, com os valores estimados a partir dos dados.

O coeficiente **-64822.33** (`ω`) representa o **impacto imediato e pontual** do evento de intervenção (no tempo $T$). Isso significa que, no momento em que ocorreu, o evento causou uma **queda estimada de aproximadamente 64.822 unidades** no nível da série.

Os outros coeficientes (`ar1=0.6219`, `ma1=-0.8848`, `sma1=-0.9295`) definem a "memória" da série, ou seja, como o efeito desse choque inicial e de outras flutuações aleatórias se dissipam e se propagam ao longo dos meses seguintes.


# Conclusão das análises e modelos


## Conclusão das análises e modelos

::: {style="font-size: 60%;"}

Avaliamos quatro modelos de duas famílias principais: **ARIMA** e **ETS**.

1.  **Regressão com Erros ARIMA (Dinâmico)**
    * `Regression with ARIMA(1,1,1)(0,1,1)[12] errors`
    * Inclui uma variável externa (`xreg`) para melhorar a previsão.

2.  **ARIMA Sazonal (SARIMA)**
    * `ARIMA(1,1,1)(0,1,1)[12]`

3.  **ARIMA Sazonal (Alternativo)**
    * `ARIMA(1,1,1)(1,0,0)[12]`

4.  **ETS (Suavização Exponencial)**
    * `ETS(M,Ad,M)` - (Erro Multiplicativo, Tendência Aditiva Amortecida, Sazonalidade Multiplicativa)

## Conclusão das análises e modelos

### **Qualidade do Ajuste vs. Complexidade**
* **AIC, AICc, BIC:** Penalizam modelos complexos para evitar sobreajuste.
* ***Quanto menor, melhor.***

#### **Acurácia da Previsão (no treino)**
* **RMSE, MAE, MAPE:** Medem o erro médio das previsões.
* ***Quanto menor, melhor.***

:::

##  Resultados: Qualidade do Ajuste 

Comparamos os critérios de informação. Valores mais baixos indicam um melhor equilíbrio entre o ajuste do modelo e sua simplicidade.

| Modelo | AIC | BIC |
| :--- | :--- | :--- |
| **Reg-ARIMA** 🏆 | **5029.19** | **5046.04** |
| ARIMA (0,1,1)[12] | 5035.95 | 5049.43 |
| ARIMA (1,0,0)[12] | 5326.89 | 5340.59 |
| ETS(M,Ad,M) | 5878.42 | 5940.15 |

**Conclusão:** O modelo **Regressão com Erros ARIMA** se mostra superior, sugerindo que a variável externa (`xreg`) adiciona valor real.

##  Resultados: Acurácia da Previsão 

Analisamos os erros de previsão no conjunto de dados de treino.

| Modelo | RMSE | MAE | MAPE (%) |
| :--- | :--- | :--- | :--- |
| **Reg-ARIMA** 🏆 | **26064.73** | **19178.95** | **2.22%** |
| ARIMA (0,1,1)[12] | 26697.04 | 19381.64 | 2.24% |
| ARIMA (1,0,0)[12] | 29490.90 | 22057.06 | 2.61% |
| ETS(M,Ad,M) | 26608.53 | 19550.13 | 2.29% |

**Conclusão:** O **Reg-ARIMA** consistentemente produz os menores erros, confirmando sua maior precisão.

---

##  O Veredito: O Modelo Vencedor 

O modelo **Regressão com Erros ARIMA(1,1,1)(0,1,1)[12]** é a escolha recomendada.

### Por que ele venceu?

* ✅ **Menores Critérios de Informação (AIC & BIC):** Melhor equilíbrio entre ajuste e complexidade.
* ✅ **Menores Erros de Previsão (RMSE & MAE):** Previsões mais acuradas.
* ✅ **Poder Explicativo Adicional:** A variável externa `xreg` é estatisticamente significativa e melhora o desempenho do modelo em relação a um ARIMA puro.




# Referências Teóricas

- Box, G. E. P., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M., *Time Series Analysis: Forecasting and Control* (Wiley Series in Probability and Statistics), 5th Edition.

- Brockwell, P. J., & Davis, R. A., *Time Series: Theory and Methods* (Springer Series in Statistics), 2nd Edition.

- Hamilton, J. D., *Time Series Analysis* (Princeton University Press), 1st Edition.

- Morettin, P. A., & Toloi, C. M. C., *Séries Temporais em R: Análise e Previsão* (Blucher), 1st Edition.

- Shumway, R. H., & Stoffer, D. S., *Time Series Analysis and Its Applications: With R Examples* (Springer Texts in Statistics), 4th Edition.

# Obrigado !! 
